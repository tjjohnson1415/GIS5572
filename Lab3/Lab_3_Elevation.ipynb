{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation_csv_path = r'C:\\Users\\tjjoh\\OneDrive\\Desktop\\GIS 5572\\Lab3\\elevation.csv'\n",
    "\n",
    "stem_path = r'C:\\Users\\tjjoh\\Documents\\GIS5572'\n",
    "gdb_name = r'Lab3GDB'\n",
    "gdb_path = stem_path + r'/' + gdb_name + '.gdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create database connection\n",
    "connection_string = f'postgresql://<user>:<password>@34.133.43.30:5432/lab2'\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "#retrieve the data from PostGIS\n",
    "table_name = \"mn_elevation\"\n",
    "query = f'SELECT *, ST_AsText(geometry) AS WKT_geom FROM {table_name};'\n",
    "\n",
    "df = pd.read_sql(query, engine) #read data with pandas\n",
    "df.to_csv(elevation_csv_path, index = False) #save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new file GDB if one doesn't exist\n",
    "try:\n",
    "    arcpy.management.CreateFileGDB(\n",
    "        out_folder_path = stem_path,\n",
    "        out_name = gdb_name,\n",
    "        out_version = 'CURRENT'\n",
    "    )\n",
    "except:\n",
    "    print('GDB already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set workspace\n",
    "arcpy.env.workspace = gdb_path\n",
    "\n",
    "#create a new feature class\n",
    "elevation = 'elevation'\n",
    "spatial_ref = arcpy.SpatialReference(4326)\n",
    "arcpy.management.CreateFeatureclass(gdb_path, elevation, 'POINT', spatial_reference = spatial_ref)\n",
    "\n",
    "#add a field for elevation to the feature class\n",
    "arcpy.management.AddField(elevation, 'elevation', 'DOUBLE')\n",
    "\n",
    "#iterate through the dataframe to populate ferature class\n",
    "cursor = arcpy.da.InsertCursor(elevation, ['SHAPE@', 'elevation'])\n",
    "for index, row in df.iterrows():\n",
    "    geometry = arcpy.FromWKT(row['wkt_geom'])  #convert WKT to geometry\n",
    "    cursor.insertRow([geometry, row['elevation']])\n",
    "\n",
    "del cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, April 17, 2025 8:11:11 PM\",\"Succeeded at Thursday, April 17, 2025 8:11:16 PM (Elapsed Time: 4.91 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\tjjoh\\\\Documents\\\\GIS5572/Lab3GDB.gdb\\\\testing'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clear selection\n",
    "arcpy.management.SelectLayerByAttribute(elevation, 'CLEAR_SELECTION')\n",
    "\n",
    "#create training and testing datasets\n",
    "training = 'training'\n",
    "testing = 'testing'\n",
    "\n",
    "#count features\n",
    "total_count = int(arcpy.GetCount_management(elevation)[0])\n",
    "\n",
    "#calculate 5% sample size\n",
    "sample_size = max(1, total_count // 20)  # Ensure at least one feature is selected\n",
    "\n",
    "#get all OBJECTIDs\n",
    "oids = [row[0] for row in arcpy.da.SearchCursor(elevation, [\"OID@\"])]\n",
    "\n",
    "#randomly select 5% of features\n",
    "random_oids = random.sample(oids, sample_size)\n",
    "\n",
    "#create selection query\n",
    "oid_query = f\"OBJECTID IN ({','.join(map(str, random_oids))})\"\n",
    "\n",
    "#select and export training data\n",
    "arcpy.management.SelectLayerByAttribute(elevation, \"NEW_SELECTION\", oid_query)\n",
    "arcpy.management.CopyFeatures(elevation, training)\n",
    "\n",
    "#create opposite selection query\n",
    "oid_query = f\"OBJECTID NOT IN ({','.join(map(str, random_oids))})\"\n",
    "\n",
    "#select and export testing data\n",
    "arcpy.management.SelectLayerByAttribute(elevation, \"NEW_SELECTION\", oid_query)\n",
    "arcpy.management.CopyFeatures(elevation, testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conduct spline interpolation on training data\n",
    "spline = arcpy.ddd.Spline(\n",
    "    in_point_features = training,\n",
    "    z_field = 'elevation',\n",
    "    out_raster = gdb_path + r'/Spline',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conduct IDW interpolation on training data\n",
    "idw = arcpy.ddd.Idw(\n",
    "    in_point_features = training,\n",
    "    z_field = 'elevation',\n",
    "    out_raster = gdb_path + r'/IDW',\n",
    "    power = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conduct Ordinary Kriging on training data\n",
    "okriging = arcpy.ddd.Kriging(\n",
    "    in_point_features = training,\n",
    "    z_field = 'elevation',\n",
    "    out_surface_raster = gdb_path + r'/OKriging',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, April 17, 2025 8:11:24 PM\",\"Succeeded at Thursday, April 17, 2025 8:11:30 PM (Elapsed Time: 5.76 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<geoprocessing server result object object at 0x0000021222E02F30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the values of the interpolated rasters to the testing data points\n",
    "arcpy.sa.ExtractMultiValuesToPoints(\n",
    "    in_point_features = testing,\n",
    "    in_rasters = 'Spline Spline;IDW IDW;OKriging OKriging',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['Spline', 'IDW', 'OKriging']\n",
    "\n",
    "#calculate error for each testing point for each method\n",
    "for method in methods:\n",
    "    arcpy.management.CalculateField(\n",
    "        in_table = testing,\n",
    "        field = f'error_{method}',\n",
    "        expression = f'!{method}! - !elevation!',\n",
    "        expression_type = 'PYTHON3',\n",
    "        field_type = 'FLOAT',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract errors for each method as a list\n",
    "error_spline = [row[0] for row in arcpy.da.SearchCursor(testing, ['error_Spline'])]\n",
    "error_idw = [row[0] for row in arcpy.da.SearchCursor(testing, ['error_IDW'])]\n",
    "error_okrig = [row[0] for row in arcpy.da.SearchCursor(testing, ['error_OKriging'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate rmse, mae, and maxae for each method\n",
    "rmse = []\n",
    "mae = []\n",
    "maxae = []\n",
    "for error in [error_spline, error_idw, error_okrig]:\n",
    "    absolute_error = [abs(x) for x in error]\n",
    "    squared_error = [x ** 2 for x in error]\n",
    "    \n",
    "    rmse.append(np.sqrt(np.mean(squared_error)))\n",
    "    mae.append(np.mean(absolute_error))\n",
    "    maxae.append(np.max(absolute_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pandas dataframe for accuracy assessment\n",
    "accuracy_assessment = pd.DataFrame({'Interpolation Method': methods,\n",
    "                                   'Root Mean Squared Error': rmse,\n",
    "                                   'Mean Absolute Error': mae,\n",
    "                                   'Maximum Absolute Error': maxae\n",
    "                                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interpolation Method</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Maximum Absolute Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spline</td>\n",
       "      <td>14.508639</td>\n",
       "      <td>7.556840</td>\n",
       "      <td>241.302750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDW</td>\n",
       "      <td>12.350837</td>\n",
       "      <td>6.678294</td>\n",
       "      <td>214.172302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OKriging</td>\n",
       "      <td>14.107064</td>\n",
       "      <td>7.959049</td>\n",
       "      <td>221.433472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Interpolation Method  ...  Maximum Absolute Error\n",
       "0               Spline  ...              241.302750\n",
       "1                  IDW  ...              214.172302\n",
       "2             OKriging  ...              221.433472\n",
       "\n",
       "[3 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully pushed to the PostGIS table 'elevation_accuracy'.\n"
     ]
    }
   ],
   "source": [
    "# Push the DataFrame to PostGIS\n",
    "table_name = 'elevation_accuracy'\n",
    "accuracy_assessment.to_sql(table_name, engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(f\"DataFrame successfully pushed to the PostGIS table '{table_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, April 17, 2025 8:12:15 PM\",\"Succeeded at Thursday, April 17, 2025 8:12:20 PM (Elapsed Time: 5.27 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\tjjoh\\\\Documents\\\\GIS5572\\\\Lab3\\\\testing_points.geojson'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_geojson = stem_path + r'\\Lab3\\testing_points.geojson'\n",
    "\n",
    "arcpy.conversion.FeaturesToJSON(\n",
    "    in_features = testing,\n",
    "    out_json_file = testing_geojson,\n",
    "    geoJSON = 'GEOJSON'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(testing_geojson, \"r\") as f:\n",
    "    geojson_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Feature', 'id': 1, 'geometry': {'type': 'Point', 'coordinates': [-95.99715165999999, 43.997147933000065]}, 'properties': {'OBJECTID': 1, 'elevation': 523.8542, 'Spline': 534.580933, 'IDW': 531.203308, 'OKriging': 528.686829, 'error_Spline': 10.7267323, 'error_IDW': 7.34910822, 'error_OKriging': 4.83262873}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geojson_data['features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21]:3: RemovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n"
     ]
    }
   ],
   "source": [
    "table_name = 'elevation_testing'\n",
    "conn = engine.connect()\n",
    "conn.execute(f\"DROP TABLE IF EXISTS {table_name};\")\n",
    "conn.execute(f\"\"\"\n",
    "    CREATE TABLE {table_name} (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        geom GEOMETRY,\n",
    "        attributes JSONB\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "i = 0\n",
    "for feature in geojson_data[\"features\"]:\n",
    "    if i < 2000:\n",
    "        geom = json.dumps(feature[\"geometry\"])  # Convert geometry to JSON\n",
    "        properties = feature[\"properties\"]  # Extract attributes\n",
    "\n",
    "        insert_query = f\"\"\"\n",
    "            INSERT INTO {table_name} (geom, attributes)\n",
    "            VALUES (ST_GeomFromGeoJSON('{geom}'), '{json.dumps(properties)}')\n",
    "        \"\"\"\n",
    "        conn.execute(insert_query)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
